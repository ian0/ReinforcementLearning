#mdp 

[[Markov Decision Process]]

### Policy

*Definition*

A policy π is a distribution over actions given states,

$π(a|s) = P[A_{t} = a | S_{t} = s]$

- A policy fully defines the behaviour of an agent
- MDP policies depend on the current state (not the history)
 - i.e. Policies are stationary (time-independent),
$A_{t} ∼ π(·|S_{t} ), ∀_{t} > 0$




