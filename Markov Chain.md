#mdp 

## Markov Chain

[[Markov Decision Process]] [[Markov Process]]

A **Markov chain** is a discrete-time **process** for which the future behaviour, given the past and the present, only depends on the present and not on the past.

- System that can be observed. What can be observed are known as states.
- States transition according to specific system dynamics
- Sequence of days, classified as either sunny or rainy
	- \[sunny, sunny, rainy, sunny...]
- We can estimate a transition matrix based on historical observations